---
primary_presenter: 'pcruz'
speaker_talk_title: 'From Document to Vector: Using OpenSearch to Store Embedding Data'
primary_title: 'From Document to Vector: Using OpenSearch to Store Embedding Data'
title: 'OpenSearchCon 2023 Session: Using OpenSearch to Store Embedding Data'
breadcrumbs:
  icon: community
  items:
    - title: OpenSearchCon
      url: /events/opensearchcon/index.html
    - title: 2023
      url: /events/opensearchcon/2023/index.html
    - title: North America
      url: /events/opensearchcon/2023/north-america/index.html
    - title: Session Summaries
      url: /events/opensearchcon/2023/north-america/sessions/index.html
session_time: "2023-09-28 - 1:15pm-1:55pm"
session_room: "Willow"
session_track: "Search"
presenters:
  - pcruz
  - aflynn
permalink: '/events/opensearchcon/2023/north-america/sessions/from-document-to-vector-using-opensearch-to-store-embedding-data.html'
youtube_video_id: '5p93QX7Ocrw'
conference_id: '2023-north-america'
---

The supporting infrastructure for large LLM jobs can be difficult and costly to set up. Storing vector data requires careful consideration of resource consumption. OpenSearch offers a straightforward way to store embeddings generated by tools like Azure OpenAI or the Natural Neural Search plugin. It also handles querying, reducing the operational overhead. This talk shows how to prepare pdf files, send them to Azureâ€™s OpenAI API to generate embeddings, and store the resulting vectors in OpenSearch. This will be running on a low maintenance Raspberry Pi cluster and Charmed OpenSearch.
