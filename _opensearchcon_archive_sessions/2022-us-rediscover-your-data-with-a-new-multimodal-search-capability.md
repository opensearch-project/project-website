---
speaker_name: 'jsharpnack'
speaker_name_full: 'James Sharpnack'
speaker_talk_title: 'Rediscover Your Data with a New Multimodal Search Capability'
primary_title: 'Rediscover Your Data with a New Multimodal Search Capability'
title: 'OpenSearchCon 2022 Session: Rediscover Your Data with a New Multimodal Search Capability'
breadcrumbs:
  icon: community
  items:
    - title: OpenSearchCon
      url: /events/opensearchcon/index.html
    - title: Archive
      url: /events/opensearchcon/archive/index.html
    - title: 2022
      url: /events/opensearchcon/archive/2022/index.html
    - title: United States
      url: /events/opensearchcon/archive/2022/us/index.html
    - title: Session Summaries
      url: /events/opensearchcon/archive/2022/us/sessions/index.html
keynote_speaker: false
session_time: "2022-09-21 - 5:00pm-5:30pm"
session_room: "Fremont Studios"
permalink: '/events/opensearchcon/archive/2022/united-states/sessions/rediscover-your-data-with-a-new-multimodal-search-capability.html'
youtube_video_id: 'sefpRfJN9CA'
conference_id: '2022-us'
presenters:
  - jsharpnack
  - xshi
---
In modern search, our databases can be any modality—text, images, tabular—and we propose to add multimodal search capabilities to OpenSearch through AutoGluon, Amazon’s open-source AutoML software. Through multimodal embeddings, we’re able to perform semantic search and retrieve data based on its contextual meaning. In this session, we’ll discuss how with these embeddings, we can detect anomalous data and assess the similarities between datasets to improve our models.
