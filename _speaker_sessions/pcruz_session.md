---
speaker_name: 'pcruz'
speaker_name_full: 'Pedro Cruz'
speaker_talk_title: 'From Document to Vector: Using OpenSearch to Store Embedding Data'
primary_title: 'From Document to Vector: Using OpenSearch to Store Embedding Data'
title: 'OpenSearchCon 2023 Session: Using OpenSearch to Store Embedding Data'
keynote_speaker: false
session_time: "2023-09-28 - 1:15pm-1:55pm"
session_room: "Willow"
session_track: "Search"
presenters:
  - pcruz
  - aflynn
permalink: '/events/opensearchcon/sessions/from-document-to-vector-using-opensearch-to-store-embedding-data.html'
---

The supporting infrastructure for large LLM jobs can be difficult and costly to set up. Storing vector data requires careful consideration of resource consumption. OpenSearch offers a straightforward way to store embeddings generated by tools like Azure OpenAI or the Natural Neural Search plugin. It also handles querying, reducing the operational overhead. This talk shows how to prepare pdf files, send them to Azureâ€™s OpenAI API to generate embeddings, and store the resulting vectors in OpenSearch. This will be running on a low maintenance Raspberry Pi cluster and Charmed OpenSearch.
