---
layout: post
title:  "Customer experience outcomes of focused, user-centered product design improvements"
authors:
  - apasun
date:   2024-03-15 0:00:10 -0700
categories:
  - community
excerpt: The OpenSearch Project invites the OpenSearch community to explore the future of search, analytics, and generative AI at the first OpenSearch user conference in Europe. Join us in Berlin on May 6 & 7 and learn how to build powerful applications and get the most out of your OpenSearch deployments.
meta_keywords: 
meta_description: 
---

## User experience challenges

Software improvements often prioritize adding new features and functionality. Product managers and developers often adopt an agile approach, adding engineering capabilities in iterative steps. Neglecting seamless user experience can lead to a fragmented journey, especially for low-code users. While high-code users might adapt, low-code users often report frustration and dissatisfaction when software updates don't actually help them achieve their goals.

When navigating software, users utilize two types of memory: episodic and semantic. Episodic memory is grounded in the sequence of time, while semantic memory is conceptual. We are capable of experiencing our online environment in both ways, and switch between the two as we navigate software. When functionality is enhanced incrementally, navigation that fails to consider the logical buildup of user tasks in a software workflow can degrade the experience. Such product experiences end up ill designed and requiring ongoing customer support to help coach, train, and assist the user.

## How to measure user experience?
The [Customer Outcome Framework](https://productmanagementuniversity.com/launches-customer-outcome-framework/) employs a top-down view of the customer experience. Customer Experience Outcomes (CXOs) [define critical tasks that a product must perform and how well those tasks must be performed](https://lithespeed.com/drive-input-customer-experience-outcomes/#:~:text=What%20is%20a%20Customer%20Experience%20Outcome%20or,a%20plan%20for%20success:%20%E2%80%9CIf%20we%20do). A comprehensive set of CXO measures may include [quality and loyalty measures](https://www.forrester.com/research/cx-index/). Additional outcome measures may include [satisfaction and frustration scores](https://www.dynatrace.com/news/blog/user-experience-score-the-one-metric-to-rule-them-all/), [UMUX](https://testscience.org/measuring-usability/#UMUX)[measures](https://testscience.org/measuring-usability/#UMUX), [UMUX-lite measures](https://testscience.org/measuring-usability/#UMUX-LITE), or [SUS scores](https://testscience.org/measuring-usability/#SUS).

## OpenSearch experience outcomes
To measure OpenSearch CXOs, we first defined [distinct users](https://opensearch.org/blog/q1-survey-results/) based on roles and domain expertise. Once we validated these, we then parsed out pivotal nodes of each user’s experience as user flows. We intentionally limited the pivotal experience nodes to 3–6 in number so that we could manage the length of the survey. For each node, we asked users to provide ratings for four measures representing their perception of the experience. We adopted UMUX scale measures to quantify satisfaction, frustration, usefulness, and usability. After each set of ratings, we invited our users to tell us how we might improve. The survey was hosted for two quarters (Q3–Q4 2023), and we obtained 130 responses in total from OpenSearch Dashboards users.

![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/InfraUser_2.2.png){: .img-fluid width="30%"}
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/InfraUser_2.3.png){: .img-fluid width="30%"}
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/InfraUser_2.4.png){: .img-fluid width="30%"}
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/DataAdmin_Graph_3.2.png){: .img-fluid width="30%"}
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/DataAdmin_Graph_3.3.png){: .img-fluid width="30%"}
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/Search_Producers_4.2.png){: .img-fluid width="30%"}
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/Security_Analytics_6.2.png){: .img-fluid width="30%"}

## Findings and areas of improvement 

Of the rated experiences, the *Security Analytics Producer* experience was best rated overall (82.58%). The *Dashboards* *Consumer* (68.98%) and *Infra Admin* experiences (69.13%) indicated opportunities for improvement. The survey results indicated that *Infra User* experiences, such as *Deployment* (63.95%) and *Migration* (69.53%), and *Dashboards* *Consumer* experiences, such as *Root Cause Analysis* (65.28%) and *Ad Hoc Analysis* (67.83%), could be improved.

These findings are helping us improve known experiences; however, we are seeking feedback on fragmented user experiences, particularly from the search and analytics user segments. We invite you to provide your feedback through the [2024 Search and Analytics Survey](https://www.research.net/r/JJGMP3R). This survey is hosted by Linux Foundation Research. Feedback data is shown in the following images. 


![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/InfraUser_Graph_2.1.png){: .img-fluid }
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/DataAdmin_Graph_3.1.png){: .img-fluid }
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/Search_Producers_4.1.png){: .img-fluid }
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/Log_Analytics_5.1.png){: .img-fluid }
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/Security_Analytics_6.1.png){: .img-fluid }
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/Analytics_Customer_7.1.png){: .img-fluid }

### References

- [https://lithespeed.com/drive-input-customer-experience-outcomes/](https://lithespeed.com/drive-input-customer-experience-outcomes/#:~:text=What%20is%20a%20Customer%20Experience%20Outcome%20or,a%20plan%20for%20success:%20%E2%80%9CIf%20we%20do)

- [https://productmanagementuniversity.com/launches-customer-outcome-framework/](https://productmanagementuniversity.com/launches-customer-outcome-framework/)

- [https://www.forrester.com/research/cx-index/](https://www.forrester.com/research/cx-index/)

- [https://testscience.org/measuring-usability/#UMUX](https://testscience.org/measuring-usability/#UMUX)

- [https://testscience.org/measuring-usability/#UMUX-LITE](https://testscience.org/measuring-usability/#UMUX-LITE)

- [https://testscience.org/measuring-usability/#SUS](https://testscience.org/measuring-usability/#SUS)

